{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTIE Formulaire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "import praw\n",
    "from classes.Document import Document \n",
    "from classes.Author import Author\n",
    "from classes.Corpus import Corpus\n",
    "from classes.Document import RedditDocument, ArxivDocument\n",
    "import datetime \n",
    "import pandas as pd \n",
    "import urllib.request\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#=========================\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du corpus\n",
    "mon_corpus = Corpus(nom=\"Corpus_article\")\n",
    "# Chargez le corpus depuis un fichier CSV la méthode load prend en parametre le chemin de votre corpus\n",
    "#mon_corpus.load('corpus.csv')\n",
    "#del(Document)\n",
    "#del(mon_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6662d231604a433fa43a92d9c0964d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Football', description='Thème Reddit:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c348d101d145b3968b296325afcead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, description='Limite Reddit:', min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4532db559bcc4f19ab86e3351014ba1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='_jjmAvQmLvyPWeH7mSTYrw', description='ID Client:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b771dfd8e745329d3e699ccd9e9007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='j7vF0wxXN9VuvOrIri3dt3W4fSvH4w', description='Secret Client:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8ff9873ede44e28a9999efeba263ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='td3', description='Utilisateur:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82b5f526167402e8b10c6334b25aa24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='foot', description='Thème Arxiv:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf04d793001f4d6e803b5b3512b52406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, description='Limite Arxiv:', min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fec78d10d514e77b08e293d23dae952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Récuperer les données', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01978691ee924fc9b117d0ca70123754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f0ca93dc3542da944b88b577bbfb59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Afficher le Corpus', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48bdd9bc03047f4bc3c496c0f927715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Charger le Corpus', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6056c72cced43da9695735f2ffddc48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Enregistrer le Corpus', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It appears that you are using PRAW in an asynchronous environment.\n",
      "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
      "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de documents avant le nettoyage : 20\n",
      "Nombre de documents après le nettoyage : 16\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "# Créer des widgets pour le formulaire Arxiv\n",
    "theme_arxiv_input = widgets.Text(value='foot', description='Thème Arxiv:')\n",
    "limit_arxiv_input = widgets.IntSlider(value=10, min=1, max=100, description='Limite Arxiv:')\n",
    "\n",
    "# Créer des widgets pour le formulaire Reddit\n",
    "theme_reddit_input = widgets.Text(value='Football', description='Thème Reddit:')\n",
    "limit_reddit_input = widgets.IntSlider(value=10, min=1, max=100, description='Limite Reddit:')\n",
    "idclient_input = widgets.Text(value='_jjmAvQmLvyPWeH7mSTYrw', description='ID Client:')\n",
    "secretclient_input = widgets.Text(value='j7vF0wxXN9VuvOrIri3dt3W4fSvH4w', description='Secret Client:')\n",
    "user_input = widgets.Text(value='td3', description='Utilisateur:')\n",
    "\n",
    "# Créer des widgets pour les boutons Afficher, Charger et Enregistrer le corpus\n",
    "button_afficher = widgets.Button(description='Afficher le Corpus')\n",
    "button_charger = widgets.Button(description='Charger le Corpus')\n",
    "button_enregistrer = widgets.Button(description='Enregistrer le Corpus')\n",
    "\n",
    "# Créer des widgets pour afficher les résultats\n",
    "result_output = widgets.Output()\n",
    "\n",
    "# Créer un bouton pour charger les données\n",
    "load_data_button = widgets.Button(description='Récuperer les données')\n",
    "\n",
    "\n",
    "# Fonction appelée lors du clic sur le bouton et qui va recuperer les données Arxiv et Reddit \n",
    "def load_data(button):\n",
    "    #PArtie REDDIT\n",
    "    global collection  # Assurez-vous de déclarer collection comme une variable globale\n",
    "    theme = theme_reddit_input.value\n",
    "    limit = limit_reddit_input.value\n",
    "    idclient = idclient_input.value\n",
    "    secretclient = secretclient_input.value\n",
    "    user = user_input.value\n",
    "\n",
    "    reddit = praw.Reddit(client_id=idclient, client_secret=secretclient, user_agent=user)\n",
    "    subr = reddit.subreddit(theme)\n",
    "\n",
    "    collection = []\n",
    "\n",
    "    for doc in subr.controversial(limit=limit):\n",
    "        titre = doc.title.replace(\"\\n\", '')\n",
    "        auteur = str(doc.author)\n",
    "        date = datetime.datetime.fromtimestamp(doc.created).strftime(\"%Y/%m/%d\")\n",
    "        url = \"https://www.reddit.com/\" + doc.permalink\n",
    "        texte = doc.selftext.replace(\"\\n\", \"\")\n",
    "\n",
    "        doc_class = Document(titre, auteur, date, url, texte)\n",
    "        collection.append(doc_class)\n",
    "        \n",
    "# ====================================================Partie Arxiv : \n",
    "#==========================chargement des données Arxiv en instanciant un objet docyment\n",
    "    theme_arxiv = theme_arxiv_input.value #Foot\n",
    "    limit_arxiv = limit_arxiv_input.value\n",
    "    url = f'http://export.arxiv.org/api/query?search_query=all:{theme_arxiv}&start=0&max_results={limit_arxiv}'\n",
    "    url_read = urllib.request.urlopen(url).read()\n",
    "   \n",
    "\n",
    "    # url_read est un \"byte stream\" qui a besoin d'être décodé\n",
    "    data =  url_read.decode()\n",
    "    dico = xmltodict.parse(data) #xmltodict permet d'obtenir un objet ~JSON\n",
    "    docs = dico['feed']['entry']\n",
    "    for doc in docs:\n",
    "        titre = doc[\"title\"].replace('\\n', '')  # On enlève les retours à la ligne\n",
    "        try:\n",
    "            authors = \", \".join([a[\"name\"] for a in doc[\"author\"]])  # On fait une liste d'auteurs, séparés par une virgule\n",
    "        except:\n",
    "            authors = doc[\"author\"][\"name\"]  # Si l'auteur est seul, pas besoin de liste\n",
    "        summary = doc[\"summary\"].replace(\"\\n\", \"\")  # On enlève les retours à la ligne\n",
    "        date = datetime.datetime.strptime(doc[\"published\"], \"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y/%m/%d\")  # Formatage de la date en année/mois/jour avec librairie datetime\n",
    "\n",
    "        doc_class = Document(titre, authors, date, doc[\"id\"], summary)  # Création du Document\n",
    "        collection.append(doc_class)  # Ajout du Document à la liste.\n",
    "        \n",
    "    # Enlever les doublons en se basant sur tout le contenu\n",
    "    seen_documents = set()\n",
    "    unique_collection = []\n",
    "\n",
    "    for doc in collection:\n",
    "        doc_tuple = (doc.titre, doc.auteur, doc.date, doc.texte, doc.type)\n",
    "        if doc_tuple not in seen_documents:\n",
    "            seen_documents.add(doc_tuple)\n",
    "            unique_collection.append(doc)\n",
    "\n",
    "    # Garder uniquement les documents avec plus de 200 caractères dans le texte\n",
    "    filtered_collection = [doc for doc in unique_collection if len(doc.texte) > 200]\n",
    "\n",
    "    # Afficher le nombre de documents avant et après le nettoyage\n",
    "    print(f\"Nombre de documents avant le nettoyage : {len(collection)}\")\n",
    "    print(f\"Nombre de documents après le nettoyage : {len(filtered_collection)}\")\n",
    "\n",
    "    # Réaffecter la liste filtrée à votre collection\n",
    "    collection = filtered_collection\n",
    "\n",
    "    #Rempli le corpus \n",
    "    for doc in collection:\n",
    "        if \"reddit\" in doc.url.lower():\n",
    "            doc.type = \"Reddit\"\n",
    "        else:\n",
    "            doc.type = \"Arxiv\"\n",
    "        mon_corpus.add(doc)\n",
    "    \n",
    "        \n",
    "    with result_output:\n",
    "        result_output.clear_output(wait=True)\n",
    "        print(\"Données chargées avec succès.\")\n",
    "            \n",
    "\n",
    "\n",
    "#=================================== Creation du corpus======================= \n",
    "## =======================================================================\n",
    "# Fonctions associées aux boutons\n",
    "def afficher_corpus(button):\n",
    "    # Logique pour afficher le corpus\n",
    "    with result_output:\n",
    "        result_output.clear_output(wait=True)\n",
    "        mon_corpus.show() \n",
    "\n",
    "def charger_corpus(button):\n",
    "    mon_corpus.load(\"corpus1.csv\") #Chemin n'hésitez à le modifier \n",
    "    with result_output:\n",
    "        result_output.clear_output(wait=True)\n",
    "        print(\"Corpus chargé avec succès Vers le chemin indiqué.\")\n",
    "\n",
    "def enregistrer_corpus(button):\n",
    "    mon_corpus.save(\"corpus1.csv\")\n",
    "    with result_output:\n",
    "        result_output.clear_output(wait=True)\n",
    "        print(\"Corpus enregistré avec succès.\")\n",
    "\n",
    "\n",
    "load_data_button.on_click(load_data)#bouton pour recuperer les données\n",
    "button_afficher.on_click(afficher_corpus)#bouton pour afficher le corpus\n",
    "button_charger.on_click(charger_corpus)#bouton pour charger le corpus depuis l'ordinateur\n",
    "button_enregistrer.on_click(enregistrer_corpus)#bouton pour enregistrer le corpus dans lordinateur \n",
    "\n",
    "# Affichage des widgets\n",
    "display(\n",
    "    theme_reddit_input, limit_reddit_input, idclient_input, secretclient_input, user_input,\n",
    "    theme_arxiv_input, limit_arxiv_input, load_data_button, result_output,\n",
    "    button_afficher, button_charger, button_enregistrer\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulaires recherches DIFFERENTES METHODES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Methode 1 : SEARCH \n",
    " Ici on va juste afficher les passages qu'on va rencontrer les mots clés dans les differents documents de notre corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff287f01bcf84879bbecb24f94bdf0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Mots-clés:', placeholder='Entrez vos mots-clés')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d87207c4e6b43189e34b215b60de6e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Rechercher', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "id2doc = mon_corpus.get_id2doc()\n",
    "# Fonction pour gérer la recherche\n",
    "def effectuer_recherche(b):\n",
    "    mots_clefs = champ_recherche.value\n",
    "    passages = mon_corpus.search(mots_clefs)\n",
    "    \n",
    "    # Afficher les résultats\n",
    "    for doc_id, passage in passages.items():\n",
    "        document = id2doc[doc_id]\n",
    "        print(f\"Document ID: {doc_id}\")\n",
    "        #print(f\"Auteur: {document.auteur}\")\n",
    "        print(f\"Passage: {passage}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Champ de recherche\n",
    "champ_recherche = widgets.Text(description=\"Mots-clés:\", placeholder=\"Entrez vos mots-clés\")\n",
    "\n",
    "# Bouton pour effectuer la recherche\n",
    "bouton_recherche = widgets.Button(description=\"Rechercher\")\n",
    "bouton_recherche.on_click(effectuer_recherche)\n",
    "\n",
    "# Afficher le formulaire\n",
    "display(champ_recherche, bouton_recherche)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methode 2 : matrice tf_idf avec mesure de similarité cos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 36)\t2.772588722239781\n",
      "  (0, 50)\t1.3862943611198906\n",
      "  (0, 56)\t2.0794415416798357\n",
      "  (0, 82)\t2.0794415416798357\n",
      "  (0, 88)\t1.6739764335716716\n",
      "  (0, 90)\t2.772588722239781\n",
      "  (0, 108)\t2.772588722239781\n",
      "  (0, 142)\t2.0794415416798357\n",
      "  (0, 181)\t2.0794415416798357\n",
      "  (0, 200)\t2.0794415416798357\n",
      "  (0, 218)\t2.0794415416798357\n",
      "  (0, 229)\t1.6739764335716716\n",
      "  (0, 232)\t1.3862943611198906\n",
      "  (0, 248)\t1.6739764335716716\n",
      "  (0, 308)\t2.0794415416798357\n",
      "  (0, 317)\t1.3862943611198906\n",
      "  (0, 318)\t2.772588722239781\n",
      "  (0, 319)\t1.6739764335716716\n",
      "  (0, 330)\t1.6739764335716716\n",
      "  (0, 332)\t2.0794415416798357\n",
      "  (0, 345)\t1.6739764335716716\n",
      "  (0, 372)\t2.0794415416798357\n",
      "  (0, 416)\t1.3862943611198906\n",
      "  (0, 435)\t2.0794415416798357\n",
      "  (0, 522)\t1.6739764335716716\n",
      "  :\t:\n",
      "  (15, 184)\t4.1588830833596715\n",
      "  (15, 185)\t2.772588722239781\n",
      "  (15, 271)\t1.6739764335716716\n",
      "  (15, 274)\t0.7493868988828214\n",
      "  (15, 286)\t2.0794415416798357\n",
      "  (15, 361)\t3.347952867143343\n",
      "  (15, 449)\t1.3862943611198906\n",
      "  (15, 456)\t2.0794415416798357\n",
      "  (15, 476)\t1.6739764335716716\n",
      "  (15, 488)\t2.0794415416798357\n",
      "  (15, 497)\t2.0794415416798357\n",
      "  (15, 518)\t2.0794415416798357\n",
      "  (15, 523)\t0.9808292530117262\n",
      "  (15, 572)\t1.6739764335716716\n",
      "  (15, 589)\t1.1631508098056809\n",
      "  (15, 591)\t1.6739764335716716\n",
      "  (15, 592)\t2.0794415416798357\n",
      "  (15, 631)\t1.3862943611198906\n",
      "  (15, 729)\t2.0794415416798357\n",
      "  (15, 738)\t2.0794415416798357\n",
      "  (15, 747)\t2.772588722239781\n",
      "  (15, 766)\t1.6739764335716716\n",
      "  (15, 783)\t6.238324625039507\n",
      "  (15, 838)\t2.0794415416798357\n",
      "  (15, 840)\t1.6739764335716716\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f523b21fab074a2999dd54ab71365d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Mots-clés:', placeholder='Entrez vos mots-clés')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e7ae637ea849e68be4e7f4b526dd9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=5, description='Top N:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9b18920879489d8d2e743b0de000cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Rechercher avec Cosinus', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score de similarité avec le document Re-weighting of somatosensory inputs from the foot and the ankle for  controlling posture during quiet standing following trunk extensor muscles  fatigue : 0.15913985887287183\n",
      "Contenu du document : The present study focused on the effects of trunk extensor muscles fatigue onpostural control during quiet standing under different somatosensory conditionsfrom the foot and the ankle. With this aim, 20 young healthy adults were askedto stand as immobile as possible in two conditions of No fatigue and Fatigue oftrunk extensor muscles. In Experiment 1 (n = 10), somatosensation from the footand the ankle was degraded by standing on a foam surface. In Experiment 2 (n =10), somatosensation from the foot and ankle was facilitated through theincreased cutaneous feedback at the foot and ankle provided by strips ofathletic tape applied across both ankle joints. The centre of foot pressuredisplacements (CoP) were recorded using a force platform. The results showedthat (1) trunk extensor muscles fatigue increased CoP displacements undernormal somatosensatory conditions (Experiment 1 and Experiment 2), (2) thisdestabilizing effect was exacerbated when somatosensation from the foot and theankle was degraded (Experiment 1), and (3) this destabilizing effect wasmitigated when somatosensation from the foot and the ankle was facilitated(Experiment 2). Altogether, the present findings evidenced re-weighting ofsensory cues for controlling posture during quiet standing following trunkextensor muscles fatigue by increasing the reliance on the somatosensory inputsfrom the foot and the ankle. This could have implications in clinical andrehabilitative areas.\n",
      "\n",
      "\n",
      "Score de similarité avec le document Software Based Higher Order Structural Foot Abnormality Detection Using  Image Processing : 0.11036018638393427\n",
      "Contenu du document : The entire movement of human body undergoes through a periodic process namedGait Cycle. The structure of human foot is the key element to complete thecycle successfully. Abnormality of this foot structure is an alarming form ofcongenital disorder which results a classification based on the geometry of thehuman foot print image. Image processing is one of the most efficient way todetermine a number of footprint parameter to detect the severeness of disorder.This paper aims to detect the Flatfoot and High Arch foot abnormalities usingone of the footprint parameters named Modified Brucken Index by biomedicalimage processing.\n",
      "\n",
      "\n",
      "Score de similarité avec le document Fast B-spline Curve Fitting by L-BFGS : 0.07929649819535042\n",
      "Contenu du document : We propose a novel method for fitting planar B-spline curves to unorganizeddata points. In traditional methods, optimization of control points and footpoints are performed in two very time-consuming steps in each iteration: 1)control points are updated by setting up and solving a linear system ofequations; and 2) foot points are computed by projecting each data point onto aB-spline curve. Our method uses the L-BFGS optimization method to optimizecontrol points and foot points simultaneously and therefore it does not need toperform either matrix computation or foot point projection in every iteration.As a result, our method is much faster than existing methods.\n",
      "\n",
      "\n",
      "Score de similarité avec le document Mobile Apps for Foot Measurement: A Scoping Review : 0.05651893234290852\n",
      "Contenu du document : With the proliferation of smart phone, a major growth in the use of appsrelated to the health category, specifically those concerned with foot healthcan be observed. Although new, these apps are being used practically forscanning feet with an aim to providing accurate information about variousproperties of the human foot. With the availability of many 'foot scanning andmeasuring apps' in the app stores, the need for an evaluation system for suchapps can be deemed necessary as little information regarding the evidence-basedquality of these apps is available. To characterize the assessment ofmeasurement techniques and essential software quality characteristics of mobilefoot measuring apps, and determine their effectiveness for potential use ascommercial professional tools for foot care health professionals such aspedorthists, podiatrists, orthotists and so on, to assist in measuring foot forcustom shoes, and for individuals to enhance the awareness of foot health andhygiene and prevention of foot-related problems. An electronic search acrossAndroid and iOS app stores was conducted between July 2020 and August 2020 forapps related to foot measurement. Mobile apps with stated goals of footmeasurement and general foot health were identified and selected by threeindependent raters and discrepancies regarding the selected apps were resolvedvia a fourth rater. Evaluation inferences found all apps failing to meet evenhalf of the measurement-specific criteria required for the proper manufacturingof custom-made footwear. 23% (6/26) of apps were found to utilize eitherexternal scanners or advanced algorithms to reconstruct 3D models of user footthat can possibly be used for ordering custom-made footwear and medical castsfor fitting irregular foot sizes and shapes. Overall, current apps for footmeasurement do not follow any specific guidelines for measurement purposes.\n",
      "\n",
      "\n",
      "Score de similarité avec le document Translation-Invariant Representation for Cumulative Foot Pressure Images : 0.017187146440310302\n",
      "Contenu du document : Human can be distinguished by different limb movements and unique groundreaction force. Cumulative foot pressure image is a 2-D cumulative groundreaction force during one gait cycle. Although it contains pressure spatialdistribution information and pressure temporal distribution information, itsuffers from several problems including different shoes and noise, when puttingit into practice as a new biometric for pedestrian identification. In thispaper, we propose a hierarchical translation-invariant representation forcumulative foot pressure images, inspired by the success of Convolutional deepbelief network for digital classification. Key contribution in our approach isdiscriminative hierarchical sparse coding scheme which helps to learn usefuldiscriminative high-level visual features. Based on the feature representationof cumulative foot pressure images, we develop a pedestrian recognition systemwhich is invariant to three different shoes and slight local shape change.Experiments are conducted on a proposed open dataset that contains more than2800 cumulative foot pressure images from 118 subjects. Evaluations suggest theeffectiveness of the proposed method and the potential of cumulative footpressure images as a biometric.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "mon_corpus.construire_mat_tfidf()\n",
    "vocab = mon_corpus.get_vocabulaire()\n",
    "#print(vocab)\n",
    "\n",
    "\n",
    "mat_tfidf = mon_corpus.get_mattdidf()\n",
    "\n",
    "# Fonction pour gérer la recherche avec la similarité cosinus\n",
    "def effectuer_recherche_cosinus(b):\n",
    "    mots_clefs_utilisateur = champ_recherche_cosinus.value\n",
    "    top_n = int(champ_top_n.value)\n",
    "\n",
    "    # Transformer les mots-clés en vecteur\n",
    "    vecteur_requete = np.zeros(len(vocab))\n",
    "    \n",
    "    mots_clefs_propres = mon_corpus.nettoyer_texte(mots_clefs_utilisateur)\n",
    "    for mot in mots_clefs_propres.split():\n",
    "        if mot in vocab:\n",
    "            mot_id = vocab[mot]['id'] - 1\n",
    "            vecteur_requete[mot_id] += 1\n",
    "\n",
    "    # Calculer la similarité cosinus\n",
    "    mat_tfidf = mon_corpus.mat_tfidf  # Assurez-vous que la matrice TF-IDF est disponible\n",
    "    similarites = cosine_similarity([vecteur_requete], mat_tfidf)\n",
    "\n",
    "    # Afficher les résultats\n",
    "    indices_tries = np.argsort(similarites[0])[::-1]\n",
    "    id2doc = mon_corpus.id2doc\n",
    "    \n",
    "    for i in range(top_n):\n",
    "        indice_document = indices_tries[i]\n",
    "        score_similarite = similarites[0, indice_document]\n",
    "        document = id2doc[indice_document]\n",
    "\n",
    "        print(f\"Score de similarité avec le document {document.titre} : {score_similarite}\")\n",
    "        print(f\"Contenu du document : {document.texte}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Champ de recherche pour la similarité cosinus\n",
    "champ_recherche_cosinus = widgets.Text(description=\"Mots-clés:\", placeholder=\"Entrez vos mots-clés\")\n",
    "\n",
    "# Champ pour spécifier le nombre de résultats à afficher\n",
    "champ_top_n = widgets.IntText(description=\"Top N:\", value=5)\n",
    "\n",
    "# Bouton pour effectuer la recherche avec la similarité cosinus\n",
    "bouton_recherche_cosinus = widgets.Button(description=\"Rechercher avec Cosinus\")\n",
    "bouton_recherche_cosinus.on_click(effectuer_recherche_cosinus)\n",
    "\n",
    "# Afficher le formulaire\n",
    "display(champ_recherche_cosinus, champ_top_n, bouton_recherche_cosinus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
