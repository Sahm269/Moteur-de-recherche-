{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTIE Formulaire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\soura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "import praw\n",
    "from classes.Document import Document \n",
    "from classes.Author import Author\n",
    "from classes.Corpus import Corpus\n",
    "from classes.Document import RedditDocument, ArxivDocument\n",
    "import datetime \n",
    "import pandas as pd \n",
    "import urllib.request\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#=========================\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du corpus\n",
    "mon_corpus = Corpus(nom=\"Corpus_article\")\n",
    "#del(Document)\n",
    "#del(mon_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2cea827a804a4592700a6365338af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Text(value='Football', description='Thème Reddit:', layout=Layout(margin='0 50px…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab1f3b8de5d4fe1b7108e31bb6e6e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Afficher le Corpus', style=ButtonStyle()), Text(value='', description='Chem…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050feb5bbd4c48ba9d4763f686ba847f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It appears that you are using PRAW in an asynchronous environment.\n",
      "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
      "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de documents avant le nettoyage : 200\n",
      "Nombre de documents après le nettoyage : 153\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "# Créer des widgets pour le formulaire Arxiv\n",
    "theme_arxiv_input = widgets.Text(value='all', description='Thème Arxiv:')\n",
    "limit_arxiv_input = widgets.IntSlider(value=10, min=1, max=100, description='Limite Arxiv:')\n",
    "\n",
    "# Créer des widgets pour le formulaire Reddit\n",
    "theme_reddit_input = widgets.Text(value='all', description='Thème Reddit:', layout={'margin': '0 50px 0 0'})\n",
    "limit_reddit_input = widgets.IntSlider(value=10, min=1, max=100, description='Limite Reddit:')\n",
    "idclient_input = widgets.Text(value='_jjmAvQmLvyPWeH7mSTYrw', description='ID Client:')\n",
    "secretclient_input = widgets.Text(value='j7vF0wxXN9VuvOrIri3dt3W4fSvH4w', description='Secret Client:')\n",
    "user_input = widgets.Text(value='td3', description='Utilisateur:')\n",
    "\n",
    "# Créer des widgets pour les boutons Afficher, Charger et Enregistrer le corpus\n",
    "button_afficher = widgets.Button(description='Afficher le Corpus')\n",
    "# Champ de texte pour le chemin du fichier\n",
    "champ_chemin_fichier = widgets.Text(description=\"Chemin du fichier:\", placeholder=\"Entrez le chemin du fichier\")\n",
    "button_charger = widgets.Button(description='Charger le Corpus')\n",
    "button_enregistrer = widgets.Button(description='Enregistrer le Corpus')\n",
    "\n",
    "# Créer des widgets pour afficher les résultats\n",
    "result_output = widgets.Output()\n",
    "\n",
    "# Créer un bouton pour charger les données\n",
    "load_data_button = widgets.Button(description='Récuperer les données')\n",
    "\n",
    "\n",
    "# Fonction appelée lors du clic sur le bouton et qui va recuperer les données Arxiv et Reddit \n",
    "def load_data(button):\n",
    "    #PArtie REDDIT\n",
    "    global collection  # Assurez-vous de déclarer collection comme une variable globale\n",
    "    theme = theme_reddit_input.value\n",
    "    limit = limit_reddit_input.value\n",
    "    idclient = idclient_input.value\n",
    "    secretclient = secretclient_input.value\n",
    "    user = user_input.value\n",
    "\n",
    "    reddit = praw.Reddit(client_id=idclient, client_secret=secretclient, user_agent=user)\n",
    "    subr = reddit.subreddit(theme)\n",
    "\n",
    "    collection = []\n",
    "\n",
    "    for doc in subr.controversial(limit=limit):\n",
    "        titre = doc.title.replace(\"\\n\", '')\n",
    "        auteur = str(doc.author)\n",
    "        date = datetime.datetime.fromtimestamp(doc.created).strftime(\"%Y/%m/%d\")\n",
    "        url = \"https://www.reddit.com/\" + doc.permalink\n",
    "        texte = doc.selftext.replace(\"\\n\", \"\")\n",
    "\n",
    "        doc_class = Document(titre, auteur, date, url, texte)\n",
    "        collection.append(doc_class)\n",
    "        \n",
    "# ====================================================Partie Arxiv : \n",
    "#==========================chargement des données Arxiv en instanciant un objet docyment\n",
    "    theme_arxiv = theme_arxiv_input.value #Foot\n",
    "    limit_arxiv = limit_arxiv_input.value\n",
    "    url = f'http://export.arxiv.org/api/query?search_query=all:{theme_arxiv}&start=0&max_results={limit_arxiv}'\n",
    "    url_read = urllib.request.urlopen(url).read()\n",
    "   \n",
    "\n",
    "    # url_read est un \"byte stream\" qui a besoin d'être décodé\n",
    "    data =  url_read.decode()\n",
    "    dico = xmltodict.parse(data) #xmltodict permet d'obtenir un objet ~JSON\n",
    "    docs = dico['feed']['entry']\n",
    "    for doc in docs:\n",
    "        titre = doc[\"title\"].replace('\\n', '')  # On enlève les retours à la ligne\n",
    "        try:\n",
    "            authors = \", \".join([a[\"name\"] for a in doc[\"author\"]])  # On fait une liste d'auteurs, séparés par une virgule\n",
    "        except:\n",
    "            authors = doc[\"author\"][\"name\"]  # Si l'auteur est seul, pas besoin de liste\n",
    "        summary = doc[\"summary\"].replace(\"\\n\", \"\")  # On enlève les retours à la ligne\n",
    "        date = datetime.datetime.strptime(doc[\"published\"], \"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y/%m/%d\")  # Formatage de la date en année/mois/jour avec librairie datetime\n",
    "\n",
    "        doc_class = Document(titre, authors, date, doc[\"id\"], summary)  # Création du Document\n",
    "        collection.append(doc_class)  # Ajout du Document à la liste.\n",
    "        \n",
    "    # Enlever les doublons en se basant sur tout le contenu\n",
    "    seen_documents = set()\n",
    "    unique_collection = []\n",
    "\n",
    "    for doc in collection:\n",
    "        doc_tuple = (doc.titre, doc.auteur, doc.date, doc.texte, doc.type)\n",
    "        if doc_tuple not in seen_documents:\n",
    "            seen_documents.add(doc_tuple)\n",
    "            unique_collection.append(doc)\n",
    "\n",
    "    # Garder uniquement les documents avec plus de 200 caractères dans le texte\n",
    "    filtered_collection = [doc for doc in unique_collection if len(doc.texte) > 200]\n",
    "\n",
    "    # Afficher le nombre de documents avant et après le nettoyage\n",
    "    print(f\"Nombre de documents avant le nettoyage : {len(collection)}\")\n",
    "    print(f\"Nombre de documents après le nettoyage : {len(filtered_collection)}\")\n",
    "\n",
    "    # Réaffecter la liste filtrée à votre collection\n",
    "    collection = filtered_collection\n",
    "\n",
    "    #Rempli le corpus \n",
    "    for doc in collection:\n",
    "        if \"reddit\" in doc.url.lower():\n",
    "            doc.type = \"Reddit\"\n",
    "        else:\n",
    "            doc.type = \"Arxiv\"\n",
    "        mon_corpus.add(doc)\n",
    "    \n",
    "        \n",
    "    with result_output:\n",
    "        result_output.clear_output(wait=True)\n",
    "        print(\"Données chargées avec succès.\")\n",
    "            \n",
    "\n",
    "\n",
    "#=================================== Creation du corpus======================= \n",
    "## =======================================================================\n",
    "# Fonctions associées aux boutons\n",
    "def afficher_corpus(button):\n",
    "    # Logique pour afficher le corpus\n",
    "    with result_output:\n",
    "        result_output.clear_output(wait=True)\n",
    "        mon_corpus.show() \n",
    "\n",
    "\n",
    "\n",
    "def enregistrer_corpus(button):\n",
    "    mon_corpus.save(\"corpus1.csv\")\n",
    "    with result_output:\n",
    "        result_output.clear_output(wait=True)\n",
    "        print(\"Corpus enregistré avec succès.\")\n",
    "        \n",
    "def charger_corpus(button):\n",
    "    chemin_fichier = champ_chemin_fichier.value\n",
    "    mon_corpus.load(chemin_fichier)\n",
    "    \n",
    "    with result_output:\n",
    "        result_output.clear_output(wait=True)\n",
    "        print(f\"Corpus chargé avec succès depuis le chemin : {chemin_fichier}\")\n",
    "\n",
    "\n",
    "\n",
    "load_data_button.on_click(load_data)#bouton pour recuperer les données\n",
    "button_afficher.on_click(afficher_corpus)#bouton pour afficher le corpus\n",
    "button_charger.on_click(charger_corpus)#bouton pour charger le corpus depuis l'ordinateur\n",
    "button_enregistrer.on_click(enregistrer_corpus)#bouton pour enregistrer le corpus dans lordinateur \n",
    "\n",
    "\n",
    "\n",
    "# Conteneurs pour organiser la mise en page\n",
    "partie_reddit = widgets.VBox([theme_reddit_input, limit_reddit_input, idclient_input, secretclient_input, user_input])\n",
    "partie_arxiv = widgets.VBox([theme_arxiv_input, limit_arxiv_input, load_data_button])\n",
    "boutons_bas = widgets.HBox([button_afficher, champ_chemin_fichier, button_charger, button_enregistrer])\n",
    "\n",
    "# Affichage final\n",
    "display(widgets.HBox([partie_reddit, partie_arxiv]), boutons_bas, result_output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moteur de  recherche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methode  1: matrice tf_idf avec mesure de similarité cos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad5be6132c3457c97c30bde2a3ec424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Mots-clés:', placeholder='Entrez vos mots-clés')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8de957b59340d296310c3d5e186115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=5, description='Top N:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719ca1882c0f4ed5ad9eb334546c8e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Rechercher', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2beac4e3e1e4d0fb0e5beb276539306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Effacer les résultats', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b109aad74514039af99b14ac666eba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Fonction pour gérer la recherche avec la similarité cosinus\n",
    "def effectuer_recherche_cosinus(b):\n",
    "    mon_corpus.construire_mat_tfidf()\n",
    "    vocab = mon_corpus.get_vocabulaire()\n",
    "    mots_clefs_utilisateur = champ_recherche_cosinus.value\n",
    "    top_n = int(champ_top_n.value)\n",
    "    vecteur_requete = np.zeros(len(vocab))\n",
    "\n",
    "    mots_clefs_propres = mon_corpus.nettoyer_texte(mots_clefs_utilisateur)\n",
    "    for mot in mots_clefs_propres.split():\n",
    "        if mot in vocab:\n",
    "            mot_id = vocab[mot]['id'] - 1\n",
    "            vecteur_requete[mot_id] += 1\n",
    "\n",
    "    #calcule la similarité\n",
    "\n",
    "    mat_tfidf = mon_corpus.get_mattdidf()\n",
    "    similarites = cosine_similarity([vecteur_requete], mat_tfidf)\n",
    "\n",
    "    indices_tries = np.argsort(similarites[0])[::-1]\n",
    "    id2doc = mon_corpus.get_id2doc()\n",
    "    \n",
    "    # zone de sortie \n",
    "    with output_recherche_cosinus:\n",
    "        # Effacer le contenu précédent\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        for i in range(top_n):\n",
    "            indice_document = indices_tries[i]\n",
    "            score_similarite = similarites[0, indice_document]\n",
    "\n",
    "            #  indexation\n",
    "            indice_document += 1\n",
    "\n",
    "            document = id2doc[indice_document]\n",
    "            \n",
    "            # Ajouter d'autres informations\n",
    "            contenu_html = f\"<p>Score de similarité avec le document {document.titre} : {score_similarite}</p>\" \\\n",
    "                           f\"<p>URL : <a href='{document.url}' target='_blank'>{document.url}</a></p>\"\\\n",
    "                           f\"<p>Contenu du document : {document.texte}</p>\" \\\n",
    "                           f\"<p>Auteur : {document.auteur}</p>\" \\\n",
    "                           f\"<p>Date : {document.date}</p>\" \\\n",
    "                           f\"<p>Type : {document.type}</p>\"\\\n",
    "                           f\"<hr>\"\n",
    "            \n",
    "            # Afficher le contenu avec HTML\n",
    "            display(HTML(contenu_html))\n",
    "\n",
    "# ...\n",
    "\n",
    "\n",
    "# Fonction pour effacer la recherche\n",
    "def effacer_recherche(b):\n",
    "    champ_recherche_cosinus.value = \"\"\n",
    "    # Effacer la sortie\n",
    "    with output_recherche_cosinus:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "# Champ de recherche pour la similarité cosinus\n",
    "champ_recherche_cosinus = widgets.Text(description=\"Mots-clés:\", placeholder=\"Entrez vos mots-clés\")\n",
    "\n",
    "# Champ pour spécifier le nombre de résultats à afficher\n",
    "champ_top_n = widgets.IntText(description=\"Top N:\", value=5)\n",
    "\n",
    "# Bouton pour effectuer la recherche avec la similarité cosinus\n",
    "bouton_recherche_cosinus = widgets.Button(description=\"Rechercher\")\n",
    "bouton_recherche_cosinus.on_click(effectuer_recherche_cosinus)\n",
    "\n",
    "# Bouton pour effacer la recherche\n",
    "bouton_effacer = widgets.Button(description=\"Effacer les résultats\")\n",
    "bouton_effacer.on_click(effacer_recherche)\n",
    "\n",
    "# Afficher le formulaire\n",
    "display(champ_recherche_cosinus, champ_top_n, bouton_recherche_cosinus, bouton_effacer)\n",
    "\n",
    "# Créer une zone de sortie pour afficher les résultats\n",
    "output_recherche_cosinus = widgets.Output()\n",
    "display(output_recherche_cosinus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
