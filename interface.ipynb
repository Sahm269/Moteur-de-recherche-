{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTIE Formulaire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "import praw\n",
    "from classes.Document import Document \n",
    "from classes.Author import Author\n",
    "from classes.Corpus import Corpus\n",
    "from classes.Document import RedditDocument, ArxivDocument\n",
    "import datetime \n",
    "import pandas as pd \n",
    "import urllib.request\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#=========================\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du corpus\n",
    "mon_corpus = Corpus(nom=\"Corpus_article\")\n",
    "#del(Document)\n",
    "#del(mon_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d543f95330437aa08f9c54a5afaf95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Text(value='Football', description='Thème Reddit:', layout=Layout(margin='0 50px…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797f03cff8a34425ad52bd442fb115d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Afficher le Corpus', style=ButtonStyle()), Text(value='', description='Chem…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec67ca3825a417fbbd1091b13e66e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It appears that you are using PRAW in an asynchronous environment.\n",
      "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
      "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de documents avant le nettoyage : 200\n",
      "Nombre de documents après le nettoyage : 153\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[142], line 131\u001b[0m, in \u001b[0;36mcharger_corpus\u001b[1;34m(button)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcharger_corpus\u001b[39m(button):\n\u001b[0;32m    130\u001b[0m     chemin_fichier \u001b[38;5;241m=\u001b[39m champ_chemin_fichier\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m--> 131\u001b[0m     mon_corpus\u001b[38;5;241m.\u001b[39mload(chemin_fichier)\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m result_output:\n\u001b[0;32m    134\u001b[0m         result_output\u001b[38;5;241m.\u001b[39mclear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\Cours\\GitHub\\Moteur-de-recherche-\\classes\\Corpus.py:78\u001b[0m, in \u001b[0;36mCorpus.load\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorpus.csv\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# Charger le corpus depuis un fichier CSV\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(filename)\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     80\u001b[0m         doc \u001b[38;5;241m=\u001b[39m Document(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitre\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAuteur\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTexte\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "# Créer des widgets pour le formulaire Arxiv\n",
    "theme_arxiv_input = widgets.Text(value='foot', description='Thème Arxiv:')\n",
    "limit_arxiv_input = widgets.IntSlider(value=10, min=1, max=100, description='Limite Arxiv:')\n",
    "\n",
    "# Créer des widgets pour le formulaire Reddit\n",
    "theme_reddit_input = widgets.Text(value='Football', description='Thème Reddit:', layout={'margin': '0 50px 0 0'})\n",
    "limit_reddit_input = widgets.IntSlider(value=10, min=1, max=100, description='Limite Reddit:')\n",
    "idclient_input = widgets.Text(value='_jjmAvQmLvyPWeH7mSTYrw', description='ID Client:')\n",
    "secretclient_input = widgets.Text(value='j7vF0wxXN9VuvOrIri3dt3W4fSvH4w', description='Secret Client:')\n",
    "user_input = widgets.Text(value='td3', description='Utilisateur:')\n",
    "\n",
    "# Créer des widgets pour les boutons Afficher, Charger et Enregistrer le corpus\n",
    "button_afficher = widgets.Button(description='Afficher le Corpus')\n",
    "# Champ de texte pour le chemin du fichier\n",
    "champ_chemin_fichier = widgets.Text(description=\"Chemin du fichier:\", placeholder=\"Entrez le chemin du fichier\")\n",
    "button_charger = widgets.Button(description='Charger le Corpus')\n",
    "button_enregistrer = widgets.Button(description='Enregistrer le Corpus')\n",
    "\n",
    "# Créer des widgets pour afficher les résultats\n",
    "result_output = widgets.Output()\n",
    "\n",
    "# Créer un bouton pour charger les données\n",
    "load_data_button = widgets.Button(description='Récuperer les données')\n",
    "\n",
    "\n",
    "# Fonction appelée lors du clic sur le bouton et qui va recuperer les données Arxiv et Reddit \n",
    "def load_data(button):\n",
    "    #PArtie REDDIT\n",
    "    global collection  # Assurez-vous de déclarer collection comme une variable globale\n",
    "    theme = theme_reddit_input.value\n",
    "    limit = limit_reddit_input.value\n",
    "    idclient = idclient_input.value\n",
    "    secretclient = secretclient_input.value\n",
    "    user = user_input.value\n",
    "\n",
    "    reddit = praw.Reddit(client_id=idclient, client_secret=secretclient, user_agent=user)\n",
    "    subr = reddit.subreddit(theme)\n",
    "\n",
    "    collection = []\n",
    "\n",
    "    for doc in subr.controversial(limit=limit):\n",
    "        titre = doc.title.replace(\"\\n\", '')\n",
    "        auteur = str(doc.author)\n",
    "        date = datetime.datetime.fromtimestamp(doc.created).strftime(\"%Y/%m/%d\")\n",
    "        url = \"https://www.reddit.com/\" + doc.permalink\n",
    "        texte = doc.selftext.replace(\"\\n\", \"\")\n",
    "\n",
    "        doc_class = Document(titre, auteur, date, url, texte)\n",
    "        collection.append(doc_class)\n",
    "        \n",
    "# ====================================================Partie Arxiv : \n",
    "#==========================chargement des données Arxiv en instanciant un objet docyment\n",
    "    theme_arxiv = theme_arxiv_input.value #Foot\n",
    "    limit_arxiv = limit_arxiv_input.value\n",
    "    url = f'http://export.arxiv.org/api/query?search_query=all:{theme_arxiv}&start=0&max_results={limit_arxiv}'\n",
    "    url_read = urllib.request.urlopen(url).read()\n",
    "   \n",
    "\n",
    "    # url_read est un \"byte stream\" qui a besoin d'être décodé\n",
    "    data =  url_read.decode()\n",
    "    dico = xmltodict.parse(data) #xmltodict permet d'obtenir un objet ~JSON\n",
    "    docs = dico['feed']['entry']\n",
    "    for doc in docs:\n",
    "        titre = doc[\"title\"].replace('\\n', '')  # On enlève les retours à la ligne\n",
    "        try:\n",
    "            authors = \", \".join([a[\"name\"] for a in doc[\"author\"]])  # On fait une liste d'auteurs, séparés par une virgule\n",
    "        except:\n",
    "            authors = doc[\"author\"][\"name\"]  # Si l'auteur est seul, pas besoin de liste\n",
    "        summary = doc[\"summary\"].replace(\"\\n\", \"\")  # On enlève les retours à la ligne\n",
    "        date = datetime.datetime.strptime(doc[\"published\"], \"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y/%m/%d\")  # Formatage de la date en année/mois/jour avec librairie datetime\n",
    "\n",
    "        doc_class = Document(titre, authors, date, doc[\"id\"], summary)  # Création du Document\n",
    "        collection.append(doc_class)  # Ajout du Document à la liste.\n",
    "        \n",
    "    # Enlever les doublons en se basant sur tout le contenu\n",
    "    seen_documents = set()\n",
    "    unique_collection = []\n",
    "\n",
    "    for doc in collection:\n",
    "        doc_tuple = (doc.titre, doc.auteur, doc.date, doc.texte, doc.type)\n",
    "        if doc_tuple not in seen_documents:\n",
    "            seen_documents.add(doc_tuple)\n",
    "            unique_collection.append(doc)\n",
    "\n",
    "    # Garder uniquement les documents avec plus de 200 caractères dans le texte\n",
    "    filtered_collection = [doc for doc in unique_collection if len(doc.texte) > 200]\n",
    "\n",
    "    # Afficher le nombre de documents avant et après le nettoyage\n",
    "    print(f\"Nombre de documents avant le nettoyage : {len(collection)}\")\n",
    "    print(f\"Nombre de documents après le nettoyage : {len(filtered_collection)}\")\n",
    "\n",
    "    # Réaffecter la liste filtrée à votre collection\n",
    "    collection = filtered_collection\n",
    "\n",
    "    #Rempli le corpus \n",
    "    for doc in collection:\n",
    "        if \"reddit\" in doc.url.lower():\n",
    "            doc.type = \"Reddit\"\n",
    "        else:\n",
    "            doc.type = \"Arxiv\"\n",
    "        mon_corpus.add(doc)\n",
    "    \n",
    "        \n",
    "    with result_output:\n",
    "        result_output.clear_output(wait=True)\n",
    "        print(\"Données chargées avec succès.\")\n",
    "            \n",
    "\n",
    "\n",
    "#=================================== Creation du corpus======================= \n",
    "## =======================================================================\n",
    "# Fonctions associées aux boutons\n",
    "def afficher_corpus(button):\n",
    "    # Logique pour afficher le corpus\n",
    "    with result_output:\n",
    "        result_output.clear_output(wait=True)\n",
    "        mon_corpus.show() \n",
    "\n",
    "\n",
    "\n",
    "def enregistrer_corpus(button):\n",
    "    mon_corpus.save(\"corpus1.csv\")\n",
    "    with result_output:\n",
    "        result_output.clear_output(wait=True)\n",
    "        print(\"Corpus enregistré avec succès.\")\n",
    "        \n",
    "def charger_corpus(button):\n",
    "    chemin_fichier = champ_chemin_fichier.value\n",
    "    mon_corpus.load(chemin_fichier)\n",
    "    \n",
    "    with result_output:\n",
    "        result_output.clear_output(wait=True)\n",
    "        print(f\"Corpus chargé avec succès depuis le chemin : {chemin_fichier}\")\n",
    "\n",
    "\n",
    "\n",
    "load_data_button.on_click(load_data)#bouton pour recuperer les données\n",
    "button_afficher.on_click(afficher_corpus)#bouton pour afficher le corpus\n",
    "button_charger.on_click(charger_corpus)#bouton pour charger le corpus depuis l'ordinateur\n",
    "button_enregistrer.on_click(enregistrer_corpus)#bouton pour enregistrer le corpus dans lordinateur \n",
    "\n",
    "\n",
    "\n",
    "# Conteneurs pour organiser la mise en page\n",
    "partie_reddit = widgets.VBox([theme_reddit_input, limit_reddit_input, idclient_input, secretclient_input, user_input])\n",
    "partie_arxiv = widgets.VBox([theme_arxiv_input, limit_arxiv_input, load_data_button])\n",
    "boutons_bas = widgets.HBox([button_afficher, champ_chemin_fichier, button_charger, button_enregistrer])\n",
    "\n",
    "# Affichage final\n",
    "display(widgets.HBox([partie_reddit, partie_arxiv]), boutons_bas, result_output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moteur de  recherche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methode  1: matrice tf_idf avec mesure de similarité cos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad5be6132c3457c97c30bde2a3ec424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Mots-clés:', placeholder='Entrez vos mots-clés')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8de957b59340d296310c3d5e186115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=5, description='Top N:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719ca1882c0f4ed5ad9eb334546c8e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Rechercher', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2beac4e3e1e4d0fb0e5beb276539306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Effacer les résultats', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b109aad74514039af99b14ac666eba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Fonction pour gérer la recherche avec la similarité cosinus\n",
    "def effectuer_recherche_cosinus(b):\n",
    "    mon_corpus.construire_mat_tfidf()\n",
    "    vocab = mon_corpus.get_vocabulaire()\n",
    "    mots_clefs_utilisateur = champ_recherche_cosinus.value\n",
    "    top_n = int(champ_top_n.value)\n",
    "    vecteur_requete = np.zeros(len(vocab))\n",
    "\n",
    "    mots_clefs_propres = mon_corpus.nettoyer_texte(mots_clefs_utilisateur)\n",
    "    for mot in mots_clefs_propres.split():\n",
    "        if mot in vocab:\n",
    "            mot_id = vocab[mot]['id'] - 1\n",
    "            vecteur_requete[mot_id] += 1\n",
    "\n",
    "    #calcule la similarité\n",
    "\n",
    "    mat_tfidf = mon_corpus.get_mattdidf()\n",
    "    similarites = cosine_similarity([vecteur_requete], mat_tfidf)\n",
    "\n",
    "    indices_tries = np.argsort(similarites[0])[::-1]\n",
    "    id2doc = mon_corpus.get_id2doc()\n",
    "    \n",
    "    # zone de sortie \n",
    "    with output_recherche_cosinus:\n",
    "        # Effacer le contenu précédent\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        for i in range(top_n):\n",
    "            indice_document = indices_tries[i]\n",
    "            score_similarite = similarites[0, indice_document]\n",
    "\n",
    "            #  indexation\n",
    "            indice_document += 1\n",
    "\n",
    "            document = id2doc[indice_document]\n",
    "            \n",
    "            # Ajouter d'autres informations\n",
    "            contenu_html = f\"<p>Score de similarité avec le document {document.titre} : {score_similarite}</p>\" \\\n",
    "                           f\"<p>URL : <a href='{document.url}' target='_blank'>{document.url}</a></p>\"\\\n",
    "                           f\"<p>Contenu du document : {document.texte}</p>\" \\\n",
    "                           f\"<p>Auteur : {document.auteur}</p>\" \\\n",
    "                           f\"<p>Date : {document.date}</p>\" \\\n",
    "                           f\"<p>Type : {document.type}</p>\"\\\n",
    "                           f\"<hr>\"\n",
    "            \n",
    "            # Afficher le contenu avec HTML\n",
    "            display(HTML(contenu_html))\n",
    "\n",
    "# ...\n",
    "\n",
    "\n",
    "# Fonction pour effacer la recherche\n",
    "def effacer_recherche(b):\n",
    "    champ_recherche_cosinus.value = \"\"\n",
    "    # Effacer la sortie\n",
    "    with output_recherche_cosinus:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "# Champ de recherche pour la similarité cosinus\n",
    "champ_recherche_cosinus = widgets.Text(description=\"Mots-clés:\", placeholder=\"Entrez vos mots-clés\")\n",
    "\n",
    "# Champ pour spécifier le nombre de résultats à afficher\n",
    "champ_top_n = widgets.IntText(description=\"Top N:\", value=5)\n",
    "\n",
    "# Bouton pour effectuer la recherche avec la similarité cosinus\n",
    "bouton_recherche_cosinus = widgets.Button(description=\"Rechercher\")\n",
    "bouton_recherche_cosinus.on_click(effectuer_recherche_cosinus)\n",
    "\n",
    "# Bouton pour effacer la recherche\n",
    "bouton_effacer = widgets.Button(description=\"Effacer les résultats\")\n",
    "bouton_effacer.on_click(effacer_recherche)\n",
    "\n",
    "# Afficher le formulaire\n",
    "display(champ_recherche_cosinus, champ_top_n, bouton_recherche_cosinus, bouton_effacer)\n",
    "\n",
    "# Créer une zone de sortie pour afficher les résultats\n",
    "output_recherche_cosinus = widgets.Output()\n",
    "display(output_recherche_cosinus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
