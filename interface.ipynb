{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTIE Formulaire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\soura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "import praw\n",
    "from classes.Document import Document \n",
    "from classes.Author import Author\n",
    "from classes.Corpus import Corpus\n",
    "from classes.Document import RedditDocument, ArxivDocument\n",
    "import datetime \n",
    "import pandas as pd \n",
    "import urllib.request\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#=========================\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du corpus\n",
    "mon_corpus = Corpus(nom=\"Corpus_article\")\n",
    "# Chargez le corpus depuis un fichier CSV la méthode load prend en parametre le chemin de votre corpus\n",
    "#mon_corpus.load('corpus.csv')\n",
    "#del(Document)\n",
    "#del(mon_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71183d22ba1407a8dfbda112fd21029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Football', description='Thème Reddit:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9612e60af7247deb8e36aa7e0374244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, description='Limite Reddit:', min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ed135f848a4c6ab10508194b2e253f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='_jjmAvQmLvyPWeH7mSTYrw', description='ID Client:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a903383665ca4558ad93d87b80466e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='j7vF0wxXN9VuvOrIri3dt3W4fSvH4w', description='Secret Client:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39decba397014dd19de3af745f983772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='td3', description='Utilisateur:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355e8f83d7384846a0c4bedb997f7fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='foot', description='Thème Arxiv:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2487e87fb0743fdb28d59cb26783d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, description='Limite Arxiv:', min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d0417e25b5435da19b480cd6219dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Récuperer les données', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ebf19b796b474da2df02399b654d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b61a8ca25454984b72ede9775fd1825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Afficher le Corpus', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd3da9d821a4550aecaba957a91a8ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Charger le Corpus', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f170aedcac974bb3ac48b3e9335c8bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Enregistrer le Corpus', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It appears that you are using PRAW in an asynchronous environment.\n",
      "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
      "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de documents avant le nettoyage : 20\n",
      "Nombre de documents après le nettoyage : 16\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "# Créer des widgets pour le formulaire Arxiv\n",
    "theme_arxiv_input = widgets.Text(value='foot', description='Thème Arxiv:')\n",
    "limit_arxiv_input = widgets.IntSlider(value=10, min=1, max=100, description='Limite Arxiv:')\n",
    "\n",
    "# Créer des widgets pour le formulaire Reddit\n",
    "theme_reddit_input = widgets.Text(value='Football', description='Thème Reddit:')\n",
    "limit_reddit_input = widgets.IntSlider(value=10, min=1, max=100, description='Limite Reddit:')\n",
    "idclient_input = widgets.Text(value='_jjmAvQmLvyPWeH7mSTYrw', description='ID Client:')\n",
    "secretclient_input = widgets.Text(value='j7vF0wxXN9VuvOrIri3dt3W4fSvH4w', description='Secret Client:')\n",
    "user_input = widgets.Text(value='td3', description='Utilisateur:')\n",
    "\n",
    "# Créer des widgets pour les boutons Afficher, Charger et Enregistrer le corpus\n",
    "button_afficher = widgets.Button(description='Afficher le Corpus')\n",
    "button_charger = widgets.Button(description='Charger le Corpus')\n",
    "button_enregistrer = widgets.Button(description='Enregistrer le Corpus')\n",
    "\n",
    "# Créer des widgets pour afficher les résultats\n",
    "result_output = widgets.Output()\n",
    "\n",
    "# Créer un bouton pour charger les données\n",
    "load_data_button = widgets.Button(description='Récuperer les données')\n",
    "\n",
    "\n",
    "# Fonction appelée lors du clic sur le bouton et qui va recuperer les données Arxiv et Reddit \n",
    "def load_data(button):\n",
    "    #PArtie REDDIT\n",
    "    global collection  # Assurez-vous de déclarer collection comme une variable globale\n",
    "    theme = theme_reddit_input.value\n",
    "    limit = limit_reddit_input.value\n",
    "    idclient = idclient_input.value\n",
    "    secretclient = secretclient_input.value\n",
    "    user = user_input.value\n",
    "\n",
    "    reddit = praw.Reddit(client_id=idclient, client_secret=secretclient, user_agent=user)\n",
    "    subr = reddit.subreddit(theme)\n",
    "\n",
    "    collection = []\n",
    "\n",
    "    for doc in subr.controversial(limit=limit):\n",
    "        titre = doc.title.replace(\"\\n\", '')\n",
    "        auteur = str(doc.author)\n",
    "        date = datetime.datetime.fromtimestamp(doc.created).strftime(\"%Y/%m/%d\")\n",
    "        url = \"https://www.reddit.com/\" + doc.permalink\n",
    "        texte = doc.selftext.replace(\"\\n\", \"\")\n",
    "\n",
    "        doc_class = Document(titre, auteur, date, url, texte)\n",
    "        collection.append(doc_class)\n",
    "        \n",
    "# ====================================================Partie Arxiv : \n",
    "#==========================chargement des données Arxiv en instanciant un objet docyment\n",
    "    theme_arxiv = theme_arxiv_input.value #Foot\n",
    "    limit_arxiv = limit_arxiv_input.value\n",
    "    url = f'http://export.arxiv.org/api/query?search_query=all:{theme_arxiv}&start=0&max_results={limit_arxiv}'\n",
    "    url_read = urllib.request.urlopen(url).read()\n",
    "   \n",
    "\n",
    "    # url_read est un \"byte stream\" qui a besoin d'être décodé\n",
    "    data =  url_read.decode()\n",
    "    dico = xmltodict.parse(data) #xmltodict permet d'obtenir un objet ~JSON\n",
    "    docs = dico['feed']['entry']\n",
    "    for doc in docs:\n",
    "        titre = doc[\"title\"].replace('\\n', '')  # On enlève les retours à la ligne\n",
    "        try:\n",
    "            authors = \", \".join([a[\"name\"] for a in doc[\"author\"]])  # On fait une liste d'auteurs, séparés par une virgule\n",
    "        except:\n",
    "            authors = doc[\"author\"][\"name\"]  # Si l'auteur est seul, pas besoin de liste\n",
    "        summary = doc[\"summary\"].replace(\"\\n\", \"\")  # On enlève les retours à la ligne\n",
    "        date = datetime.datetime.strptime(doc[\"published\"], \"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y/%m/%d\")  # Formatage de la date en année/mois/jour avec librairie datetime\n",
    "\n",
    "        doc_class = Document(titre, authors, date, doc[\"id\"], summary)  # Création du Document\n",
    "        collection.append(doc_class)  # Ajout du Document à la liste.\n",
    "        \n",
    "    # Enlever les doublons en se basant sur tout le contenu\n",
    "    seen_documents = set()\n",
    "    unique_collection = []\n",
    "\n",
    "    for doc in collection:\n",
    "        doc_tuple = (doc.titre, doc.auteur, doc.date, doc.texte, doc.type)\n",
    "        if doc_tuple not in seen_documents:\n",
    "            seen_documents.add(doc_tuple)\n",
    "            unique_collection.append(doc)\n",
    "\n",
    "    # Garder uniquement les documents avec plus de 200 caractères dans le texte\n",
    "    filtered_collection = [doc for doc in unique_collection if len(doc.texte) > 200]\n",
    "\n",
    "    # Afficher le nombre de documents avant et après le nettoyage\n",
    "    print(f\"Nombre de documents avant le nettoyage : {len(collection)}\")\n",
    "    print(f\"Nombre de documents après le nettoyage : {len(filtered_collection)}\")\n",
    "\n",
    "    # Réaffecter la liste filtrée à votre collection\n",
    "    collection = filtered_collection\n",
    "\n",
    "    #Rempli le corpus \n",
    "    for doc in collection:\n",
    "        if \"reddit\" in doc.url.lower():\n",
    "            doc.type = \"Reddit\"\n",
    "        else:\n",
    "            doc.type = \"Arxiv\"\n",
    "        mon_corpus.add(doc)\n",
    "    \n",
    "        \n",
    "    with result_output:\n",
    "        result_output.clear_output(wait=True)\n",
    "        print(\"Données chargées avec succès.\")\n",
    "            \n",
    "\n",
    "\n",
    "#=================================== Creation du corpus======================= \n",
    "## =======================================================================\n",
    "# Fonctions associées aux boutons\n",
    "def afficher_corpus(button):\n",
    "    # Logique pour afficher le corpus\n",
    "    with result_output:\n",
    "        result_output.clear_output(wait=True)\n",
    "        mon_corpus.show() \n",
    "\n",
    "def charger_corpus(button):\n",
    "    mon_corpus.load(\"corpus1.csv\") #Chemin n'hésitez à le modifier \n",
    "    with result_output:\n",
    "        result_output.clear_output(wait=True)\n",
    "        print(\"Corpus chargé avec succès Vers le chemin indiqué.\")\n",
    "\n",
    "def enregistrer_corpus(button):\n",
    "    mon_corpus.save(\"corpus1.csv\")\n",
    "    with result_output:\n",
    "        result_output.clear_output(wait=True)\n",
    "        print(\"Corpus enregistré avec succès.\")\n",
    "\n",
    "\n",
    "load_data_button.on_click(load_data)#bouton pour recuperer les données\n",
    "button_afficher.on_click(afficher_corpus)#bouton pour afficher le corpus\n",
    "button_charger.on_click(charger_corpus)#bouton pour charger le corpus depuis l'ordinateur\n",
    "button_enregistrer.on_click(enregistrer_corpus)#bouton pour enregistrer le corpus dans lordinateur \n",
    "\n",
    "# Affichage des widgets\n",
    "display(\n",
    "    theme_reddit_input, limit_reddit_input, idclient_input, secretclient_input, user_input,\n",
    "    theme_arxiv_input, limit_arxiv_input, load_data_button, result_output,\n",
    "    button_afficher, button_charger, button_enregistrer\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulaires recherches DIFFERENTES METHODES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Methode 1 : SEARCH \n",
    " Ici on va juste afficher les passages qu'on va rencontrer les mots clés dans les differents documents de notre corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff287f01bcf84879bbecb24f94bdf0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Mots-clés:', placeholder='Entrez vos mots-clés')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d87207c4e6b43189e34b215b60de6e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Rechercher', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "id2doc = mon_corpus.get_id2doc()\n",
    "# Fonction pour gérer la recherche\n",
    "def effectuer_recherche(b):\n",
    "    mots_clefs = champ_recherche.value\n",
    "    passages = mon_corpus.search(mots_clefs)\n",
    "    \n",
    "    # Afficher les résultats\n",
    "    for doc_id, passage in passages.items():\n",
    "        document = id2doc[doc_id]\n",
    "        print(f\"Document ID: {doc_id}\")\n",
    "        #print(f\"Auteur: {document.auteur}\")\n",
    "        print(f\"Passage: {passage}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Champ de recherche\n",
    "champ_recherche = widgets.Text(description=\"Mots-clés:\", placeholder=\"Entrez vos mots-clés\")\n",
    "\n",
    "# Bouton pour effectuer la recherche\n",
    "bouton_recherche = widgets.Button(description=\"Rechercher\")\n",
    "bouton_recherche.on_click(effectuer_recherche)\n",
    "\n",
    "# Afficher le formulaire\n",
    "display(champ_recherche, bouton_recherche)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methode 2 : matrice tf_idf avec mesure de similarité cos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c13c4af47434ac8a6d6dad01e57da57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Mots-clés:', placeholder='Entrez vos mots-clés')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0bdca863d84115a2eabee1779e658d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=5, description='Top N:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5f2d63032c471c94b76dac9d627397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Rechercher avec Cosinus', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7e5eb233ab405c8c1a505d4f637e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Effacer les résultats', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35cf0f82124c4efc8ebd14017faaca6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ...\n",
    "\n",
    "# Fonction pour gérer la recherche avec la similarité cosinus\n",
    "def effectuer_recherche_cosinus(b):\n",
    "    mon_corpus.construire_mat_tfidf()\n",
    "    vocab = mon_corpus.get_vocabulaire()\n",
    "    mots_clefs_utilisateur = champ_recherche_cosinus.value\n",
    "    top_n = int(champ_top_n.value)\n",
    "    vecteur_requete = np.zeros(len(vocab))\n",
    "\n",
    "    mots_clefs_propres = mon_corpus.nettoyer_texte(mots_clefs_utilisateur)\n",
    "    for mot in mots_clefs_propres.split():\n",
    "        if mot in vocab:\n",
    "            mot_id = vocab[mot]['id'] - 1\n",
    "            vecteur_requete[mot_id] += 1\n",
    "\n",
    "    #calcule la similarité\n",
    "\n",
    "    mat_tfidf = mon_corpus.get_mattdidf()\n",
    "    similarites = cosine_similarity([vecteur_requete], mat_tfidf)\n",
    "\n",
    "    indices_tries = np.argsort(similarites[0])[::-1]\n",
    "    id2doc = mon_corpus.get_id2doc()\n",
    "    \n",
    "    # Utiliser une zone de sortie au lieu de print\n",
    "    with output_recherche_cosinus:\n",
    "        # Effacer le contenu précédent\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        for i in range(top_n):\n",
    "            indice_document = indices_tries[i]\n",
    "            score_similarite = similarites[0, indice_document]\n",
    "\n",
    "            # Assurez-vous que l'indice est décalé de 1 pour correspondre à votre indexation\n",
    "            indice_document += 1\n",
    "\n",
    "            document = id2doc[indice_document]\n",
    "\n",
    "            print(f\"Score de similarité avec le document {document.titre} : {score_similarite}\")\n",
    "            print(f\"Contenu du document : {document.texte}\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "# Fonction pour effacer la recherche\n",
    "def effacer_recherche(b):\n",
    "    champ_recherche_cosinus.value = \"\"\n",
    "    # Effacer la sortie\n",
    "    with output_recherche_cosinus:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "# Champ de recherche pour la similarité cosinus\n",
    "champ_recherche_cosinus = widgets.Text(description=\"Mots-clés:\", placeholder=\"Entrez vos mots-clés\")\n",
    "\n",
    "# Champ pour spécifier le nombre de résultats à afficher\n",
    "champ_top_n = widgets.IntText(description=\"Top N:\", value=5)\n",
    "\n",
    "# Bouton pour effectuer la recherche avec la similarité cosinus\n",
    "bouton_recherche_cosinus = widgets.Button(description=\"Rechercher avec Cosinus\")\n",
    "bouton_recherche_cosinus.on_click(effectuer_recherche_cosinus)\n",
    "\n",
    "# Bouton pour effacer la recherche\n",
    "bouton_effacer = widgets.Button(description=\"Effacer les résultats\")\n",
    "bouton_effacer.on_click(effacer_recherche)\n",
    "\n",
    "# Afficher le formulaire\n",
    "display(champ_recherche_cosinus, champ_top_n, bouton_recherche_cosinus, bouton_effacer)\n",
    "\n",
    "# Créer une zone de sortie pour afficher les résultats\n",
    "output_recherche_cosinus = widgets.Output()\n",
    "display(output_recherche_cosinus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
